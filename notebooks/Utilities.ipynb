{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is the utilities file which has the common utility fuctions to be used across all classes, from here functions can be used\n",
    "which helps in achieving code reusability\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,balanced_accuracy_score,classification_report\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This function used to generate augmented images for the training data\n",
    "\"\"\"\n",
    "def return_Augmented_Images():\n",
    "    return tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.resnet50.preprocess_input,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.4,0.8],\n",
    "    width_shift_range=[-50,0,50,30,-30],\n",
    "    zoom_range=0.1,\n",
    "    fill_mode=\"nearest\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This function used to generate augmented images for the training data\n",
    "\"\"\"\n",
    "def return_no_Augmentation_Images():\n",
    "    return tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        preprocessing_function=tf.keras.applications.resnet50.preprocess_input,)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function used to plot the loss and accuracy for training and validation data\n",
    "\"\"\"\n",
    "def plot_loss_acc(model,model_name):\n",
    "    fig=plt.figure()\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.plot(model.history.history[\"loss\"])\n",
    "    plt.plot(model.history.history[\"val_loss\"])\n",
    "    plt.title(f\"{model_name} \\n Model loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend({\"train\",\"valid\"})\n",
    "\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(model.history.history[\"accuracy\"])\n",
    "    plt.plot(model.history.history[\"val_accuracy\"])\n",
    "    plt.title(\"Model Accuracy\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend({\"train\",\"valid\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function is used to plot confusion matrix for visualizg the certain things\n",
    "\"\"\"\n",
    "def plot_confusion_matrix(ytrue,ypred,class_names,model_name):\n",
    "    cm=confusion_matrix(y_true=ytrue.labels,y_pred=np.argmax(ypred,axis=1),)\n",
    "    normlazied_cm=cm.astype(\"float\")/cm.sum(axis=1)[:,np.newaxis]\n",
    "    plt.subplots(figsize=(6,6))\n",
    "    sns.heatmap(normlazied_cm,annot=True,fmt=\".2f\",cmap=\"Purples\",xticklabels=class_names,yticklabels=class_names)\n",
    "    plt.title(f\"Confusion Matrix - {model_name}\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(data,name,model):\n",
    "    score_model=model.evaluate(data,verbose=1)\n",
    "    print(f\"{name} loss: {score_model[0]:.2f}\")\n",
    "    print(f\"{name} accuracy: {score_model[1]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_data(data,model):\n",
    "    predict_model=model.predict(data)\n",
    "    return predict_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(y_test,y_pred,model_name):\n",
    "    accuracy=accuracy_score(y_test,y_pred)\n",
    "    balanced_acc=balanced_accuracy_score(y_test,y_pred)\n",
    "    print(f\"Accuracy Score: {model_name}:{accuracy:.2f}\")\n",
    "    print(f\"Balanced Accuracy Score: {model_name}:{balanced_acc:.2f}\")\n",
    "    print(\"\\n\")\n",
    "    print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
